<!DOCTYPE html>
<html lang="zh-CN">

<head>
    <meta charset="UTF-8">
<meta name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

    <meta name="author" content="Yoson Ling">





<title>LLM 与 KG 的结合案例 Demo | Yoson&#39;s Blog</title>



    <link rel="icon" href="/ai.ico">




    <!-- stylesheets list from _config.yml -->
    
    <link rel="stylesheet" href="/css/style.css">
    



    <!-- scripts list from _config.yml -->
    
    <script src="/js/script.js"></script>
    
    <script src="/js/tocbot.min.js"></script>
    



    
    
        
    


<meta name="generator" content="Hexo 5.4.2"></head>

<body>
    <script>
        // this function is used to check current theme before page loaded.
        (() => {
            const currentTheme = window.localStorage && window.localStorage.getItem('theme') || '';
            const isDark = currentTheme === 'dark';
            const pagebody = document.getElementsByTagName('body')[0]
            if (isDark) {
                pagebody.classList.add('dark-theme');
                // mobile
                document.getElementById("mobile-toggle-theme").innerText = "· Dark"
            } else {
                pagebody.classList.remove('dark-theme');
                // mobile
                document.getElementById("mobile-toggle-theme").innerText = "· Light"
            }
        })();
    </script>

    <div class="wrapper">
        <header>
    <nav class="navbar">
        <div class="container">
            <div class="navbar-header header-logo"><a href="/">Yoson&#39;s Blog</a></div>
            <div class="menu navbar-right">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/category">Categories</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
                    <a class="menu-item" href="/about">About</a>
                
                <input id="switch_default" type="checkbox" class="switch_default">
                <label for="switch_default" class="toggleBtn"></label>
            </div>
        </div>
    </nav>

    
    <nav class="navbar-mobile" id="nav-mobile">
        <div class="container">
            <div class="navbar-header">
                <div>
                    <a href="/">Yoson&#39;s Blog</a><a id="mobile-toggle-theme">·&nbsp;Light</a>
                </div>
                <div class="menu-toggle" onclick="mobileBtn()">&#9776; Menu</div>
            </div>
            <div class="menu" id="mobile-menu">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/category">Categories</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
                    <a class="menu-item" href="/about">About</a>
                
            </div>
        </div>
    </nav>

</header>
<script>
    var mobileBtn = function f() {
        var toggleMenu = document.getElementsByClassName("menu-toggle")[0];
        var mobileMenu = document.getElementById("mobile-menu");
        if(toggleMenu.classList.contains("active")){
           toggleMenu.classList.remove("active")
            mobileMenu.classList.remove("active")
        }else{
            toggleMenu.classList.add("active")
            mobileMenu.classList.add("active")
        }
    }
</script>
            <div class="main">
                <div class="container">
    
    
        <div class="post-toc">
    <div class="tocbot-list">
    </div>
    <div class="tocbot-list-menu">
        <a class="tocbot-toc-expand" onclick="expand_toc()">Expand all</a>
        <a onclick="go_top()">Back to top</a>
        <a onclick="go_bottom()">Go to bottom</a>
    </div>
</div>

<script>
    var tocbot_timer;
    var DEPTH_MAX = 6; // 为 6 时展开所有
    var tocbot_default_config = {
        tocSelector: '.tocbot-list',
        contentSelector: '.post-content',
        headingSelector: 'h1, h2, h3, h4, h5',
        orderedList: false,
        scrollSmooth: true,
        onClick: extend_click,
    };

    function extend_click() {
        clearTimeout(tocbot_timer);
        tocbot_timer = setTimeout(function() {
            tocbot.refresh(obj_merge(tocbot_default_config, {
                hasInnerContainers: true
            }));
        }, 420); // 这个值是由 tocbot 源码里定义的 scrollSmoothDuration 得来的
    }

    document.ready(function() {
        tocbot.init(obj_merge(tocbot_default_config, {
            collapseDepth: 1
        }));
    });

    function expand_toc() {
        var b = document.querySelector('.tocbot-toc-expand');
        var expanded = b.getAttribute('data-expanded');
        expanded ? b.removeAttribute('data-expanded') : b.setAttribute('data-expanded', true);
        tocbot.refresh(obj_merge(tocbot_default_config, {
            collapseDepth: expanded ? 1 : DEPTH_MAX
        }));
        b.innerText = expanded ? 'Expand all' : 'Collapse all';
    }

    function go_top() {
        window.scrollTo(0, 0);
    }

    function go_bottom() {
        window.scrollTo(0, document.body.scrollHeight);
    }

    function obj_merge(target, source) {
        for (var item in source) {
            if (source.hasOwnProperty(item)) {
                target[item] = source[item];
            }
        }
        return target;
    }
</script>
    

    
    <article class="post-wrap">
        <header class="post-header">
            <h1 class="post-title">LLM 与 KG 的结合案例 Demo</h1>
            
                <div class="post-meta">
                    
                        Author: <a itemprop="author" rel="author" href="/">Yoson Ling</a>
                    

                    
                        <span class="post-time">
                        Date: <a href="#">九月 20, 2023&nbsp;&nbsp;00:00:00</a>
                        </span>
                    
                    
                        <span class="post-category">
                    Category:
                            
                                <a href="/categories/Project/">Project</a>
                            
                        </span>
                    
                </div>
            
        </header>

        <div class="post-content">
            <h1 id="关于-NebulaGraph"><a href="#关于-NebulaGraph" class="headerlink" title="关于 NebulaGraph"></a>关于 NebulaGraph</h1><p>一个可靠的分布式、线性扩容、 性能高效的图数据库，擅长处理千亿节点万亿条边的超大数据集，同时保持毫秒级查询延时的图数据库解决方案</p>
<h2 id="部署-NebulaGraph-集群"><a href="#部署-NebulaGraph-集群" class="headerlink" title="部署 NebulaGraph 集群"></a>部署 NebulaGraph 集群</h2><h3 id="使用-Docker-Compose-部署-NebulaGraph-集群"><a href="#使用-Docker-Compose-部署-NebulaGraph-集群" class="headerlink" title="使用 Docker Compose 部署 NebulaGraph 集群"></a>使用 Docker Compose 部署 NebulaGraph 集群</h3><p>参考资料：<a target="_blank" rel="noopener" href="https://docs.nebula-graph.com.cn/">https://docs.nebula-graph.com.cn/</a></p>
<blockquote>
<p>使用 Docker Compose 可以基于准备好的配置文件快速部署 NebulaGraph 服务，仅建议在测试NebulaGraph 功能时使用该方式</p>
</blockquote>
<p>主机 Linux 系统：Ubuntu 20.04.6</p>
<p><strong>安装 Docker</strong></p>
<blockquote>
<p>使用 Apt repository 进行安装</p>
<p>参考文档：<a target="_blank" rel="noopener" href="https://docs.docker.com/engine/install/ubuntu/#install-using-the-repository">https://docs.docker.com/engine/install/ubuntu/#install-using-the-repository</a></p>
</blockquote>
<ol>
<li>创建 Docker 的 Apt repository.</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Add Docker<span class="string">&#x27;s official GPG key:</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="string">sudo apt-get update</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="string">sudo apt-get install ca-certificates curl gnupg</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="string">sudo install -m 0755 -d /etc/apt/keyrings</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="string">curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="string">sudo chmod a+r /etc/apt/keyrings/docker.gpg</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">Add the repository to Apt sources:</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="string">echo \</span></span></span><br><span class="line"><span class="string"><span class="language-bash">  &quot;deb [arch=&quot;$(dpkg --print-architecture)&quot; signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \</span></span></span><br><span class="line"><span class="string"><span class="language-bash">  &quot;$(. /etc/os-release &amp;&amp; echo &quot;$VERSION_CODENAME&quot;)&quot; stable&quot; | \</span></span></span><br><span class="line"><span class="string"><span class="language-bash">  sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="string">sudo apt-get update</span></span></span><br></pre></td></tr></table></figure>

<ol start="2">
<li>安装最新的 Docker packages</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin</span></span><br></pre></td></tr></table></figure>

<ol start="3">
<li>验证 Docker Engine 是否安装成功</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo docker run hello-world</span></span><br></pre></td></tr></table></figure>

<p><strong>安装 Docker Compose</strong></p>
<blockquote>
<p>参考文档：<a target="_blank" rel="noopener" href="https://docs.docker.com/compose/install/standalone/">https://docs.docker.com/compose/install/standalone/</a></p>
</blockquote>
<ol>
<li>下载并安装 Compose standalone</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl -SL https://github.com/docker/compose/releases/download/v2.20.3/docker-compose-linux-x86_64 -o /usr/local/bin/docker-compose</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo <span class="built_in">chmod</span> +x /usr/local/bin/docker-compose</span></span><br></pre></td></tr></table></figure>

<ol start="2">
<li>验证 Compose standalone 是否安装成功</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker-compose</span></span><br></pre></td></tr></table></figure>

<p><strong>部署 NebulaGraph</strong></p>
<ol>
<li>通过 Git 克隆 <code>nebula-docker-compose</code> 仓库的分支到主机，并切换工作目录</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">git <span class="built_in">clone</span> -b release-3.6 https://github.com/vesoft-inc/nebula-docker-compose.git</span></span><br></pre></td></tr></table></figure>

<p>注：执行该命令时出现报错 <code>GnuTLS recv error (-54): Error in the pull function</code>，没有解决，尝试将 <code>release-3.6</code> 更换为 <code>release-3.5</code> 之后连接超时，没有解决，尝试将 <code>release-3.6</code> 更换为 <code>release-3.4</code> 之后成功克隆仓库（具体原因未知）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> nebula-docker-compose</span></span><br></pre></td></tr></table></figure>

<ol start="2">
<li>启动 NebulaGraph 服务</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker-compose up -d</span></span><br></pre></td></tr></table></figure>

<p><strong>连接 NebulaGraph</strong>（两种方式）</p>
<ol>
<li><p>在容器外通过 Nebula Console 连接</p>
<blockquote>
<p>因为容器配置文件中将 Graph 服务的外部映射端口也固定为 9669，因此可以直接通过默认端口连接</p>
</blockquote>
<ul>
<li><p>下载所需版本的 NebulaGraph Console 二进制文件</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/vesoft-inc/nebula-console/releases">https://github.com/vesoft-inc/nebula-console/releases</a></li>
</ul>
</li>
<li><p>可选：重命名文件为 <code>nebula-console</code>（方便使用）</p>
</li>
<li><p>授予 <code>nebula-console</code> 文件的执行权限： <code>sudo chmod 111 nebula-console</code></p>
</li>
<li><p>运行 <code>nebula-console</code>，连接 NebulaGraph</p>
  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">./nebula-console -addr 127.0.0.1 -port 9669 -u root -p nebula</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>登录安装了 NebulaGraph Console 的容器，然后再连接 Graph 服务</p>
 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker <span class="built_in">exec</span> -it nebuladockercompose_console_1 /bin/sh</span></span><br></pre></td></tr></table></figure>

 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/ # ./usr/local/bin/nebula-console -u root -p nebula --address=graphd --port=9669</span><br></pre></td></tr></table></figure></li>
</ol>
<p><strong>查看 NebulaGraph 服务的状态和端口</strong></p>
<blockquote>
<p>NebulaGraph 默认使用 <code>9669</code> 端口为客户端提供服务，如果需要修改端口，需要修改目录 <code>nebula-docker-compose</code> 内的文件 <code>docker-compose.yaml</code>，然后重启 NebulaGraph 服务</p>
</blockquote>
 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">docker-compose ps</span></span><br></pre></td></tr></table></figure>

<p><strong>关闭 NebulaGraph 服务</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo docker-compose down</span></span><br></pre></td></tr></table></figure>

<h1 id="关于-LLM-与-KG-的结合"><a href="#关于-LLM-与-KG-的结合" class="headerlink" title="关于 LLM 与 KG 的结合"></a>关于 LLM 与 KG 的结合</h1><h1 id="核心内容概述"><a href="#核心内容概述" class="headerlink" title="核心内容概述"></a>核心内容概述</h1><h2 id="要点总结"><a href="#要点总结" class="headerlink" title="要点总结"></a><strong>要点总结</strong></h2><p>整个 Demo 对 LLM 与 KG 的结合作出了一定的探索并已经将具体实现整合到 langchain 与 llama_index 中，大致分为三个方向（其中，第一个方向主要涉及借助 LLM 构建 KG，后两个方向主要涉及借助 KG 增强 LLM）：</p>
<ul>
<li><strong>Construct</strong> <strong>KG</strong> <strong>via</strong> <strong>LLM</strong>：从已有的文档中按照确定的规则抽取知识（三元组）并存入图数据库中</li>
<li><strong>Text2Cypher</strong>：对于用户提出的问题，由 LLM 将自然语言的询问转换为对图数据库的 Cypher 查询，获取到查询结果后，再经由 LLM 整合并输出回答 (类似 <a target="_blank" rel="noopener" href="https://hugegraph.feishu.cn/wiki/JqfPwpg61iCm4QklTp6cOpcDnEd">前端 Hubble 打通 LLM 方案梳理</a>)</li>
<li><strong>Graph</strong> <strong>RAG</strong>：对于用户提出的问题，由 LLM 提取问题中所涉及的 Entity，以此来从 KG 中获取与问题相关的 sub-KG 作为上下文，再由 LLM 对该上下文信息进行理解并输出回答（该方法分为两个使用场景：一是使用 llama_index 等框架/工具基于已有的文档构建 KG 并使用，二是基于已有的 KG 使用，案例中两者均给出了具体实现）<ul>
<li>对比 <strong>Vector RAG</strong>：与 Graph RAG 不同的地方在于，将文档（构建 KG 的原始文档）分为多个 chunk，通过向量搜索找到 K 个最语义相关的 chunk 作为 上下文信息</li>
<li>尝试 <strong>Graph</strong> <strong>+</strong> <strong>Vector</strong> <strong>RAG</strong>：结合 Graph RAG 与 Vector RAG （并与单独的 Vector RAG 和单独的 Graph RAG 对比效果）</li>
</ul>
</li>
</ul>
<h2 id="实验结论"><a href="#实验结论" class="headerlink" title="实验结论"></a><strong>实验结论</strong></h2><p>原作者针对 Demo 进行了对比试验，实验结果指出：</p>
<ul>
<li>pure-KG-based 和 otherwise：<ul>
<li>Text2Cypher 和 Graph RAG 均能给出精确的答案，并且 Token 开销远小于 Vector RAG 和 Graph + Vector RAG<ul>
<li>关于此处 Token 开销，原作者仅在实验文档中对比了 Response 的 Token 数量而没有对比 Prompt 的 Token 数量</li>
<li>pure-KG-based 方法得到的回答更加简短精炼（作者想表达的意思应该是其信息密度较高 ）</li>
</ul>
</li>
<li>Graph + Vector RAG 在问题涉及的知识广泛分布在文档的<strong>不同段落</strong>时，能够给出更加综合和完整的回答 (意思是说 –&gt; 更适合复杂问题?)</li>
</ul>
</li>
<li>Text2Cypher 和 Graph RAG：<ul>
<li>Text2Cypher 仅结合查询结果作出回答，Graph RAG 结合所有相关上下文进行回答，因此，对于答案本身属于细节性、碎片性信息的，Text2Cypher 效果更好，反之 Graph RAG 效果更好</li>
<li>对于以下情形优先使用 Graph RAG：<ul>
<li>需要考虑潜在相关信息</li>
<li>KG 的 schema 相对复杂</li>
<li>KG 本身的数据质量不高</li>
<li>问题包含多个 Starting Entity</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="详细复现过程"><a href="#详细复现过程" class="headerlink" title="详细复现过程"></a>详细复现过程</h1><ol>
<li>添加环境变量</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&#x27;OPENAI_API_KEY&#x27;</span>] = <span class="string">&#x27;sk-xxxxxxxxxxx&#x27;</span> </span><br><span class="line">os.environ[<span class="string">&#x27;NEBULA_USER&#x27;</span>] = <span class="string">&#x27;root&#x27;</span></span><br><span class="line">os.environ[<span class="string">&#x27;NEBULA_PASSWORD&#x27;</span>] = <span class="string">&#x27;nebula&#x27;</span></span><br><span class="line">os.environ[<span class="string">&#x27;NEBULA_ADDRESS&#x27;</span>] = <span class="string">&#x27;127.0.0.1:9669&#x27;</span></span><br></pre></td></tr></table></figure>

<ol>
<li>图数据库的 space 创建与 schema 定义（in nebula-console）</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> SPACE guardians(vid_type<span class="operator">=</span>FIXED_STRING(<span class="number">256</span>), partition_num<span class="operator">=</span><span class="number">1</span>, replica_factor<span class="operator">=</span><span class="number">1</span>);</span><br><span class="line">USE guardians;</span><br><span class="line"><span class="keyword">CREATE</span> TAG entity(name string);</span><br><span class="line"><span class="keyword">CREATE</span> EDGE relationship(relationship string);</span><br><span class="line"><span class="keyword">CREATE</span> TAG INDEX entity_index <span class="keyword">ON</span> entity(name(<span class="number">256</span>));</span><br></pre></td></tr></table></figure>

<ol>
<li>LLM 服务的构建与准备</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> llama_index <span class="keyword">import</span> LLMPredictor</span><br><span class="line"><span class="keyword">from</span> llama_index.llms <span class="keyword">import</span> OpenAI</span><br><span class="line"><span class="keyword">from</span> llama_index <span class="keyword">import</span> ServiceContext</span><br><span class="line"></span><br><span class="line">llm = OpenAI(model=<span class="string">&#x27;text-davinci-002&#x27;</span>, temperature=<span class="number">0</span>)</span><br><span class="line">service_context = ServiceContext.from_defaults(llm=llm, chunk_size=<span class="number">512</span>)</span><br></pre></td></tr></table></figure>

<ol>
<li>图存储的构建与准备（基于 NebulaGraph）</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> llama_index.graph_stores <span class="keyword">import</span> NebulaGraphStore</span><br><span class="line"><span class="keyword">from</span> llama_index.storage.storage_context <span class="keyword">import</span> StorageContext</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&#x27;NEBULA_USER&#x27;</span>] = <span class="string">&#x27;root&#x27;</span></span><br><span class="line">os.environ[<span class="string">&#x27;NEBULA_PASSWORD&#x27;</span>] = <span class="string">&#x27;nebula&#x27;</span></span><br><span class="line">os.environ[<span class="string">&#x27;NEBULA_ADDRESS&#x27;</span>] = <span class="string">&#x27;127.0.0.1:9669&#x27;</span></span><br><span class="line">space_name = <span class="string">&#x27;guardians&#x27;</span></span><br><span class="line">edge_types, rel_prop_names= [<span class="string">&#x27;relationship&#x27;</span>], [<span class="string">&#x27;relationship&#x27;</span>]</span><br><span class="line">tags = [<span class="string">&#x27;entity&#x27;</span>]</span><br><span class="line">graph_store = NebulaGraphStore(</span><br><span class="line">    space_name=space_name,</span><br><span class="line">    edge_types=edge_types,</span><br><span class="line">    rel_prop_names=rel_prop_names,</span><br><span class="line">    tags=tags,</span><br><span class="line">)</span><br><span class="line">storage_context = StorageContext.from_defaults(graph_store=graph_store)</span><br></pre></td></tr></table></figure>

<ol>
<li>样例文档数据的准备</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> llama_index <span class="keyword">import</span> download_loader</span><br><span class="line"></span><br><span class="line">WikipediaReader = download_loader(<span class="string">&#x27;WikipediaReader&#x27;</span>)</span><br><span class="line">loader = WikipediaReader()</span><br><span class="line">documents = loader.load_data(pages=[<span class="string">&#x27;Guardians of the Galaxy Vol. 3&#x27;</span>], auto_suggest=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<ol>
<li>提取文档中的知识并存入图数据库（for Cypher Query &amp; Graph RAG）</li>
</ol>
<blockquote>
<p>Construct KG via LLM 的核心步骤</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> llama_index <span class="keyword">import</span> KnowledgeGraphIndex</span><br><span class="line"></span><br><span class="line">kg_index = KnowledgeGraphIndex.from_documents(</span><br><span class="line">    documents=documents,</span><br><span class="line">    storage_context=storage_context,</span><br><span class="line">    max_triplets_per_chunk=<span class="number">10</span>,</span><br><span class="line">    service_context=service_context,</span><br><span class="line">    space_name=space_name,</span><br><span class="line">    edge_types=edge_types,</span><br><span class="line">    rel_prop_names=rel_prop_names,</span><br><span class="line">    tags=tags,</span><br><span class="line">    include_embeddings=<span class="literal">True</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<ol>
<li>为文档生成向量索引（for Vector RAG）</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> llama_index <span class="keyword">import</span> VectorStoreIndex</span><br><span class="line"></span><br><span class="line">vector_index = VectorStoreIndex.from_documents(</span><br><span class="line">    documents=documents,</span><br><span class="line">    service_context=service_context</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<ol>
<li>将相关数据固定在磁盘并支持重复读取（可选）</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> llama_index <span class="keyword">import</span> load_index_from_storage</span><br><span class="line"><span class="keyword">from</span> llama_index.storage.storage_context <span class="keyword">import</span> StorageContext</span><br><span class="line">  </span><br><span class="line">kg_index.storage_context.persist(persist_dir=<span class="string">&#x27;./storage_graph&#x27;</span>)</span><br><span class="line">vector_index.storage_context.persist(persist_dir=<span class="string">&#x27;./storage_vector&#x27;</span>)</span><br><span class="line"></span><br><span class="line">storage_context = StorageContext.from_defaults(</span><br><span class="line">    persist_dir=<span class="string">&#x27;./storage_graph&#x27;</span>,</span><br><span class="line">    graph_store=graph_store,</span><br><span class="line">)</span><br><span class="line">kg_index = load_index_from_storage(</span><br><span class="line">    storage_context=storage_context,</span><br><span class="line">    service_context=service_context,</span><br><span class="line">    max_triplets_per_chunk=<span class="number">10</span>,</span><br><span class="line">    space_name=space_name,</span><br><span class="line">    edge_types=edge_types,</span><br><span class="line">    rel_prop_names=rel_prop_names,</span><br><span class="line">    tags=tags,</span><br><span class="line">    include_embeddings=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line">  </span><br><span class="line">storage_context_vector = StorageContext.from_defaults(persist_dir=<span class="string">&#x27;./storage_vector&#x27;</span>)</span><br><span class="line">vector_index = load_index_from_storage(</span><br><span class="line">    service_context=service_context,</span><br><span class="line">    storage_context=storage_context_vector,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<ol>
<li>Text2Cypher 的构建</li>
</ol>
<blockquote>
<p>Text2Cypher 的核心步骤</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> llama_index.query_engine <span class="keyword">import</span> KnowledgeGraphQueryEngine</span><br><span class="line"><span class="keyword">from</span> llama_index.storage.storage_context <span class="keyword">import</span> StorageContext</span><br><span class="line"><span class="keyword">from</span> llama_index.graph_stores <span class="keyword">import</span> NebulaGraphStore</span><br><span class="line"></span><br><span class="line">nl2kg_query_engine = KnowledgeGraphQueryEngine(</span><br><span class="line">    storage_context=storage_context,</span><br><span class="line">    service_context=service_context,</span><br><span class="line">    llm=llm,</span><br><span class="line">    verbose=<span class="literal">True</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<ol>
<li>Graph RAG 的构建</li>
</ol>
<blockquote>
<p>Graph RAG 的核心步骤</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">kg_rag_query_engine = kg_index.as_query_engine(</span><br><span class="line">    include_text=<span class="literal">False</span>,</span><br><span class="line">    retriever_mode=<span class="string">&#x27;keyword&#x27;</span>,</span><br><span class="line">    response_mode=<span class="string">&#x27;tree_summarize&#x27;</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># OR</span></span><br><span class="line"><span class="keyword">from</span> llama_index.query_engine <span class="keyword">import</span> RetrieverQueryEngine</span><br><span class="line"><span class="keyword">from</span> llama_index.retrievers <span class="keyword">import</span> KnowledgeGraphRAGRetriever</span><br><span class="line"></span><br><span class="line">graph_rag_retriever = KnowledgeGraphRAGRetriever(</span><br><span class="line">    storage_context=storage_context,</span><br><span class="line">    service_context=service_context,</span><br><span class="line">    llm=llm,</span><br><span class="line">    verbose=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line">kg_rag_query_engine = RetrieverQueryEngine.from_args(</span><br><span class="line">    retriever=graph_rag_retriever,</span><br><span class="line">    service_context=service_context,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<ol>
<li>Vector RAG 的构建</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vector_rag_query_engine = vector_index.as_query_engine()</span><br></pre></td></tr></table></figure>

<ol>
<li>Graph + Vector RAG 的构建</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> llama_index <span class="keyword">import</span> QueryBundle</span><br><span class="line"><span class="keyword">from</span> llama_index.schema <span class="keyword">import</span> NodeWithScore</span><br><span class="line"><span class="keyword">from</span> llama_index.retrievers <span class="keyword">import</span> BaseRetriever, VectorIndexRetriever, KGTableRetriever</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CustomRetriever</span>(<span class="title class_ inherited__">BaseRetriever</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Custom retriever that performs both Vector search and Knowledge Graph search&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        vector_retriever: VectorIndexRetriever,</span></span><br><span class="line"><span class="params">        kg_retriever: KGTableRetriever,</span></span><br><span class="line"><span class="params">        mode: <span class="built_in">str</span> = <span class="string">&quot;OR&quot;</span>,</span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Init params.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        self._vector_retriever = vector_retriever</span><br><span class="line">        self._kg_retriever = kg_retriever</span><br><span class="line">        <span class="keyword">if</span> mode <span class="keyword">not</span> <span class="keyword">in</span> (<span class="string">&quot;AND&quot;</span>, <span class="string">&quot;OR&quot;</span>):</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;Invalid mode.&quot;</span>)</span><br><span class="line">        self._mode = mode</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_retrieve</span>(<span class="params">self, query_bundle: QueryBundle</span>) -&gt; <span class="type">List</span>[NodeWithScore]:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Retrieve nodes given query.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        vector_nodes = self._vector_retriever.retrieve(query_bundle)</span><br><span class="line">        kg_nodes = self._kg_retriever.retrieve(query_bundle)</span><br><span class="line"></span><br><span class="line">        vector_ids = &#123;n.node.node_id <span class="keyword">for</span> n <span class="keyword">in</span> vector_nodes&#125;</span><br><span class="line">        kg_ids = &#123;n.node.node_id <span class="keyword">for</span> n <span class="keyword">in</span> kg_nodes&#125;</span><br><span class="line"></span><br><span class="line">        combined_dict = &#123;n.node.node_id: n <span class="keyword">for</span> n <span class="keyword">in</span> vector_nodes&#125;</span><br><span class="line">        combined_dict.update(&#123;n.node.node_id: n <span class="keyword">for</span> n <span class="keyword">in</span> kg_nodes&#125;)</span><br><span class="line"></span><br><span class="line">        retrieve_ids = vector_ids.intersection(kg_ids) <span class="keyword">if</span> self._mode == <span class="string">&quot;AND&quot;</span> <span class="keyword">else</span> vector_ids.union(kg_ids)</span><br><span class="line"></span><br><span class="line">        retrieve_nodes = [combined_dict[rid] <span class="keyword">for</span> rid <span class="keyword">in</span> retrieve_ids]</span><br><span class="line">        <span class="keyword">return</span> retrieve_nodes</span><br><span class="line"><span class="keyword">from</span> llama_index <span class="keyword">import</span> get_response_synthesizer</span><br><span class="line"><span class="keyword">from</span> llama_index.query_engine <span class="keyword">import</span> RetrieverQueryEngine</span><br><span class="line"></span><br><span class="line"><span class="comment"># create custom retriever</span></span><br><span class="line">vector_retriever = VectorIndexRetriever(index=vector_index)</span><br><span class="line">kg_retriever = KGTableRetriever(</span><br><span class="line">    index=kg_index,</span><br><span class="line">    retriever_mode=<span class="string">&quot;keyword&quot;</span>,</span><br><span class="line">    include_text=<span class="literal">False</span>,</span><br><span class="line">)</span><br><span class="line">custom_retriever = CustomRetriever(vector_retriever, kg_retriever)</span><br><span class="line"></span><br><span class="line"><span class="comment"># create response synthesizer</span></span><br><span class="line">response_synthesizer = get_response_synthesizer(</span><br><span class="line">    service_context=service_context,</span><br><span class="line">    response_mode=<span class="string">&quot;tree_summarize&quot;</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">graph_vector_rag_query_engine = RetrieverQueryEngine(</span><br><span class="line">    retriever=custom_retriever,</span><br><span class="line">    response_synthesizer=response_synthesizer,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<ol>
<li>提问并获取回答</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">seperator = <span class="string">&#x27;\n&#x27;</span> + <span class="string">&#x27;#&#x27;</span>*<span class="number">50</span> + <span class="string">&#x27;\n&#x27;</span></span><br><span class="line"></span><br><span class="line">response_nl2kg = nl2kg_query_engine.query(<span class="string">&quot;Tell me about Peter Quill.&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(response_nl2kg, end=seperator)</span><br><span class="line"></span><br><span class="line">graph_query = nl2kg_query_engine.generate_query(<span class="string">&quot;Tell me about Peter Quill?&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(graph_query.replace(<span class="string">&quot;WHERE&quot;</span>, <span class="string">&quot;\n  WHERE&quot;</span>).replace(<span class="string">&quot;RETURN&quot;</span>, <span class="string">&quot;\nRETURN&quot;</span>), end=seperator)</span><br><span class="line"></span><br><span class="line">response_graph_rag = kg_rag_query_engine.query(<span class="string">&quot;Tell me about Peter Quill.&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(response_graph_rag, end=seperator)</span><br><span class="line"></span><br><span class="line">response_vector_rag = vector_rag_query_engine.query(<span class="string">&quot;Tell me about Peter Quill.&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(response_vector_rag, end=seperator)</span><br><span class="line"></span><br><span class="line">response_graph_vector_rag = graph_vector_rag_query_engine.query(<span class="string">&quot;Tell me about Peter Quill.&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(response_graph_vector_rag, end=seperator)</span><br></pre></td></tr></table></figure>

<p><strong>经代码整合后的完整案例复现代码如下：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span>, <span class="type">Optional</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> llama_index <span class="keyword">import</span> KnowledgeGraphIndex, VectorStoreIndex</span><br><span class="line"><span class="keyword">from</span> llama_index <span class="keyword">import</span> QueryBundle</span><br><span class="line"><span class="keyword">from</span> llama_index <span class="keyword">import</span> ServiceContext</span><br><span class="line"><span class="keyword">from</span> llama_index <span class="keyword">import</span> download_loader</span><br><span class="line"><span class="keyword">from</span> llama_index <span class="keyword">import</span> get_response_synthesizer</span><br><span class="line"><span class="keyword">from</span> llama_index <span class="keyword">import</span> load_index_from_storage</span><br><span class="line"><span class="keyword">from</span> llama_index.graph_stores <span class="keyword">import</span> NebulaGraphStore</span><br><span class="line"><span class="keyword">from</span> llama_index.indices.knowledge_graph.retrievers <span class="keyword">import</span> KGRetrieverMode</span><br><span class="line"><span class="keyword">from</span> llama_index.indices.query.base <span class="keyword">import</span> BaseQueryEngine</span><br><span class="line"><span class="keyword">from</span> llama_index.llms <span class="keyword">import</span> OpenAI</span><br><span class="line"><span class="keyword">from</span> llama_index.llms.base <span class="keyword">import</span> LLM</span><br><span class="line"><span class="keyword">from</span> llama_index.response_synthesizers <span class="keyword">import</span> ResponseMode</span><br><span class="line"><span class="keyword">from</span> llama_index.retrievers <span class="keyword">import</span> BaseRetriever, VectorIndexRetriever, KGTableRetriever</span><br><span class="line"><span class="keyword">from</span> llama_index.schema <span class="keyword">import</span> NodeWithScore</span><br><span class="line"><span class="keyword">from</span> llama_index.storage.storage_context <span class="keyword">import</span> StorageContext</span><br><span class="line"><span class="keyword">from</span> llama_index.query_engine <span class="keyword">import</span> RetrieverQueryEngine, KnowledgeGraphQueryEngine</span><br><span class="line"><span class="keyword">from</span> llama_index.retrievers <span class="keyword">import</span> KnowledgeGraphRAGRetriever</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CustomRetriever</span>(<span class="title class_ inherited__">BaseRetriever</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Custom retriever that performs both Vector search and Knowledge Graph search&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        vector_retriever: VectorIndexRetriever,</span></span><br><span class="line"><span class="params">        kg_retriever: KGTableRetriever,</span></span><br><span class="line"><span class="params">        mode: <span class="built_in">str</span> = <span class="string">&quot;OR&quot;</span>,</span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Init params.&quot;&quot;&quot;</span></span><br><span class="line">        self._vector_retriever = vector_retriever</span><br><span class="line">        self._kg_retriever = kg_retriever</span><br><span class="line">        <span class="keyword">if</span> mode <span class="keyword">not</span> <span class="keyword">in</span> (<span class="string">&quot;AND&quot;</span>, <span class="string">&quot;OR&quot;</span>):</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;Invalid mode.&quot;</span>)</span><br><span class="line">        self._mode = mode</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_retrieve</span>(<span class="params">self, query_bundle: QueryBundle</span>) -&gt; <span class="type">List</span>[NodeWithScore]:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Retrieve nodes given query.&quot;&quot;&quot;</span></span><br><span class="line">        vector_nodes = self._vector_retriever.retrieve(query_bundle)</span><br><span class="line">        kg_nodes = self._kg_retriever.retrieve(query_bundle)</span><br><span class="line">        vector_ids = &#123;n.node.node_id <span class="keyword">for</span> n <span class="keyword">in</span> vector_nodes&#125;</span><br><span class="line">        kg_ids = &#123;n.node.node_id <span class="keyword">for</span> n <span class="keyword">in</span> kg_nodes&#125;</span><br><span class="line">        combined_dict = &#123;n.node.node_id: n <span class="keyword">for</span> n <span class="keyword">in</span> vector_nodes&#125;</span><br><span class="line">        combined_dict.update(&#123;n.node.node_id: n <span class="keyword">for</span> n <span class="keyword">in</span> kg_nodes&#125;)</span><br><span class="line">        retrieve_ids = vector_ids.intersection(kg_ids) <span class="keyword">if</span> self._mode == <span class="string">&quot;AND&quot;</span> <span class="keyword">else</span> vector_ids.union(kg_ids)</span><br><span class="line">        retrieve_nodes = [combined_dict[rid] <span class="keyword">for</span> rid <span class="keyword">in</span> retrieve_ids]</span><br><span class="line">        <span class="keyword">return</span> retrieve_nodes</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">prepare_llm</span>() -&gt; LLM:</span><br><span class="line">    <span class="keyword">return</span> OpenAI(model=<span class="string">&#x27;text-davinci-002&#x27;</span>, temperature=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">prepare_service_context</span>(<span class="params">llm: LLM</span>) -&gt; ServiceContext:</span><br><span class="line">    service_context = ServiceContext.from_defaults(llm=llm, chunk_size=<span class="number">512</span>)</span><br><span class="line">    <span class="keyword">return</span> service_context</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">prepare_storage_context</span>(<span class="params">mode: <span class="built_in">str</span> = <span class="string">&#x27;reload&#x27;</span></span>) -&gt; (<span class="built_in">tuple</span>, StorageContext):</span><br><span class="line">    space_name = <span class="string">&#x27;guardians&#x27;</span></span><br><span class="line">    edge_types, rel_prop_names = [<span class="string">&#x27;relationship&#x27;</span>], [<span class="string">&#x27;relationship&#x27;</span>]</span><br><span class="line">    tags = [<span class="string">&#x27;entity&#x27;</span>]</span><br><span class="line">    graph_store = NebulaGraphStore(</span><br><span class="line">        space_name=space_name,</span><br><span class="line">        edge_types=edge_types,</span><br><span class="line">        rel_prop_names=rel_prop_names,</span><br><span class="line">        tags=tags,</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">if</span> mode == <span class="string">&#x27;reload&#x27;</span>:</span><br><span class="line">        storage_context = StorageContext.from_defaults(</span><br><span class="line">            persist_dir=<span class="string">&#x27;./storage_graph&#x27;</span>,</span><br><span class="line">            graph_store=graph_store,</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        storage_context = StorageContext.from_defaults(graph_store=graph_store)</span><br><span class="line">    <span class="keyword">return</span> (space_name, edge_types, rel_prop_names, tags), storage_context</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">prepare_data</span>() -&gt; <span class="literal">None</span>:</span><br><span class="line">    llm = prepare_llm()</span><br><span class="line">    service_context = prepare_service_context(llm)</span><br><span class="line">    kg_settings, storage_context = prepare_storage_context(mode=<span class="string">&#x27;prepare&#x27;</span>)</span><br><span class="line">    space_name, edge_types, rel_prop_names, tags = kg_settings</span><br><span class="line">    WikipediaReader = download_loader(<span class="string">&#x27;WikipediaReader&#x27;</span>)</span><br><span class="line">    loader = WikipediaReader()</span><br><span class="line">    documents = loader.load_data(</span><br><span class="line">        pages=[<span class="string">&#x27;Guardians of the Galaxy Vol. 3&#x27;</span>],</span><br><span class="line">        auto_suggest=<span class="literal">False</span>,</span><br><span class="line">    )</span><br><span class="line">    kg_index = KnowledgeGraphIndex.from_documents(</span><br><span class="line">        documents=documents,</span><br><span class="line">        storage_context=storage_context,</span><br><span class="line">        max_triplets_per_chunk=<span class="number">10</span>,</span><br><span class="line">        service_context=service_context,</span><br><span class="line">        space_name=space_name,</span><br><span class="line">        edge_types=edge_types,</span><br><span class="line">        rel_prop_names=rel_prop_names,</span><br><span class="line">        tags=tags,</span><br><span class="line">        include_embeddings=<span class="literal">True</span>,</span><br><span class="line">    )</span><br><span class="line">    kg_index.storage_context.persist(persist_dir=<span class="string">&#x27;./storage_graph&#x27;</span>)</span><br><span class="line">    vector_index = VectorStoreIndex.from_documents(</span><br><span class="line">        documents=documents,</span><br><span class="line">        service_context=service_context</span><br><span class="line">    )</span><br><span class="line">    vector_index.storage_context.persist(persist_dir=<span class="string">&#x27;./storage_vector&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_query_engin</span>(<span class="params">method: <span class="built_in">str</span>, llm: LLM</span>) -&gt; <span class="type">Optional</span>[BaseQueryEngine]:</span><br><span class="line">    <span class="keyword">if</span> method == <span class="string">&#x27;graph-rag-prebuilt&#x27;</span>:</span><br><span class="line">        service_context = prepare_service_context(llm=llm)</span><br><span class="line">        kg_settings, storage_context = prepare_storage_context()</span><br><span class="line">        space_name, edge_types, rel_prop_names, tags = kg_settings</span><br><span class="line">        kg_index = load_index_from_storage(</span><br><span class="line">            storage_context=storage_context,</span><br><span class="line">            service_context=service_context,</span><br><span class="line">            max_triplets_per_chunk=<span class="number">10</span>,</span><br><span class="line">            space_name=space_name,</span><br><span class="line">            edge_types=edge_types,</span><br><span class="line">            rel_prop_names=rel_prop_names,</span><br><span class="line">            tags=tags,</span><br><span class="line">            include_embeddings=<span class="literal">True</span>,</span><br><span class="line">        )</span><br><span class="line">        query_engine = kg_index.as_query_engine(</span><br><span class="line">            include_text=<span class="literal">False</span>,</span><br><span class="line">            retriever_mode=<span class="string">&#x27;keyword&#x27;</span>,</span><br><span class="line">            response_mode=<span class="string">&#x27;tree_summarize&#x27;</span>,</span><br><span class="line">            verbose=<span class="literal">True</span>,</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">elif</span> method == <span class="string">&#x27;graph-rag-existing&#x27;</span>:</span><br><span class="line">        service_context = prepare_service_context(llm=llm)</span><br><span class="line">        _, storage_context = prepare_storage_context(mode=<span class="string">&#x27;no-index&#x27;</span>)</span><br><span class="line">        graph_rag_retriever = KnowledgeGraphRAGRetriever(</span><br><span class="line">            storage_context=storage_context,</span><br><span class="line">            service_context=service_context,</span><br><span class="line">            llm=llm,</span><br><span class="line">            verbose=<span class="literal">True</span>,</span><br><span class="line">        )</span><br><span class="line">        query_engine = RetrieverQueryEngine.from_args(</span><br><span class="line">            retriever=graph_rag_retriever,</span><br><span class="line">            service_context=service_context,</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">elif</span> method == <span class="string">&#x27;vector-rag&#x27;</span>:</span><br><span class="line">        service_context = prepare_service_context(llm=llm)</span><br><span class="line">        storage_context_vector = StorageContext.from_defaults(persist_dir=<span class="string">&#x27;./storage_vector&#x27;</span>)</span><br><span class="line">        vector_index = load_index_from_storage(</span><br><span class="line">            service_context=service_context,</span><br><span class="line">            storage_context=storage_context_vector</span><br><span class="line">        )</span><br><span class="line">        query_engine = vector_index.as_query_engine()</span><br><span class="line">    <span class="keyword">elif</span> method == <span class="string">&#x27;text-to-cypher&#x27;</span>:</span><br><span class="line">        service_context = prepare_service_context(llm=llm)</span><br><span class="line">        _, storage_context = prepare_storage_context()</span><br><span class="line">        query_engine = KnowledgeGraphQueryEngine(</span><br><span class="line">            storage_context=storage_context,</span><br><span class="line">            service_context=service_context,</span><br><span class="line">            llm=llm,</span><br><span class="line">            verbose=<span class="literal">True</span>,</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">elif</span> method == <span class="string">&#x27;graph-vector-rag&#x27;</span> <span class="keyword">or</span> <span class="string">&#x27;vector-graph-rag&#x27;</span>:</span><br><span class="line">        service_context = prepare_service_context(llm=llm)</span><br><span class="line">        storage_context_vector = StorageContext.from_defaults(persist_dir=<span class="string">&#x27;./storage_vector&#x27;</span>)</span><br><span class="line">        vector_index = load_index_from_storage(</span><br><span class="line">            service_context=service_context,</span><br><span class="line">            storage_context=storage_context_vector</span><br><span class="line">        )</span><br><span class="line">        kg_settings, storage_context = prepare_storage_context()</span><br><span class="line">        space_name, edge_types, rel_prop_names, tags = kg_settings</span><br><span class="line">        kg_index = load_index_from_storage(</span><br><span class="line">            storage_context=storage_context,</span><br><span class="line">            service_context=service_context,</span><br><span class="line">            max_triplets_per_chunk=<span class="number">10</span>,</span><br><span class="line">            space_name=space_name,</span><br><span class="line">            edge_types=edge_types,</span><br><span class="line">            rel_prop_names=rel_prop_names,</span><br><span class="line">            tags=tags,</span><br><span class="line">            include_embeddings=<span class="literal">True</span>,</span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># create custom retriever</span></span><br><span class="line">        vector_retriever = VectorIndexRetriever(index=vector_index)</span><br><span class="line">        kg_retriever = KGTableRetriever(</span><br><span class="line">            index=kg_index,</span><br><span class="line">            retriever_mode=KGRetrieverMode.KEYWORD,</span><br><span class="line">            include_text=<span class="literal">False</span>,</span><br><span class="line">        )</span><br><span class="line">        custom_retriever = CustomRetriever(vector_retriever, kg_retriever)</span><br><span class="line">        <span class="comment"># create response synthesizer</span></span><br><span class="line">        response_synthesizer = get_response_synthesizer(</span><br><span class="line">            service_context=service_context,</span><br><span class="line">            response_mode=ResponseMode.TREE_SUMMARIZE,</span><br><span class="line">        )</span><br><span class="line">        query_engine = RetrieverQueryEngine(</span><br><span class="line">            retriever=custom_retriever,</span><br><span class="line">            response_synthesizer=response_synthesizer</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Invalid method!&#x27;</span>)</span><br><span class="line">        query_engine = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">return</span> query_engine</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">print_response</span>(<span class="params">response: <span class="built_in">str</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">    result = response.split(<span class="string">&#x27;.&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> result:</span><br><span class="line">        sentence = <span class="string">f&#x27;<span class="subst">&#123;line.strip()&#125;</span>.&#x27;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(sentence.strip()) &gt; <span class="number">1</span>:</span><br><span class="line">            <span class="built_in">print</span>(sentence)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># prepare_data()</span></span><br><span class="line">    llm = prepare_llm()</span><br><span class="line">    <span class="comment"># query_engin = get_query_engin(method=&#x27;vector-rag&#x27;, llm=llm)</span></span><br><span class="line">    <span class="comment"># query_engin = get_query_engin(method=&#x27;text-to-cypher&#x27;, llm=llm)</span></span><br><span class="line">    <span class="comment"># query_engin = get_query_engin(method=&#x27;graph-rag-prebuilt&#x27;, llm=llm)</span></span><br><span class="line">    <span class="comment"># query_engin = get_query_engin(method=&#x27;graph-rag-existing&#x27;, llm=llm)</span></span><br><span class="line">    query_engin = get_query_engin(method=<span class="string">&#x27;graph-vector-rag&#x27;</span>, llm=llm)</span><br><span class="line">    <span class="keyword">if</span> query_engin <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        response = query_engin.query(<span class="string">&#x27;Tell me about Peter Quill.&#x27;</span>)</span><br><span class="line">        print_response(response.response)</span><br></pre></td></tr></table></figure>

<h1 id="源码实现细节"><a href="#源码实现细节" class="headerlink" title="源码实现细节"></a>源码实现细节</h1><h2 id="Text2Cypher-过程解析"><a href="#Text2Cypher-过程解析" class="headerlink" title="Text2Cypher 过程解析"></a>Text2Cypher 过程解析</h2><ul>
<li><code>service_context</code> 对象提供 LLM 服务的上下文（可用其他 LLM 替换 OpenAI 提供的服务）</li>
<li><code>storage_context</code> 对象提供图数据库存储的上下文<ul>
<li>由 <code>NebulaGraphStore</code> 类实现（<code>./llama_index/graph_stores/nebulagraph.py</code>）</li>
<li> 继承自 <code>GraphStore</code> 类（<code>./llama_index/graph_stores/types.py</code> ）</li>
</ul>
</li>
<li><code>query_engine</code> 对象提供向图数据库进行查询的接口<ul>
<li>由 <code>KnowledgeGraphQueryEngine</code> 类实现（<code>./llama_index/query_engine/knowledge_graph_query_engine.py</code> ）</li>
<li>使用 <code>service_context</code> 对象与 <code>storage_context</code> 对象作为参数实例化<code>KnowledgeGraphQueryEngine</code> 类</li>
<li>在与 LLM 交互时使用了为 NebulaGraph 定制的提示模板（<code>./llama_index/query_engine/knowledge_graph_query_engine.py</code> ）</li>
</ul>
</li>
<li><code>query_engine</code> 对象的 <code>query</code> 方法完成了提示词构建以及与 LLM 和 KG 的交互<ul>
<li>自然语言转换为查询语句 &amp; 通过查询语句从图数据库中得到查询结果（<strong>Retrieve</strong>）</li>
<li>查询结果转换为自然语言回答（<strong>Response Synthesize</strong>）</li>
</ul>
</li>
</ul>
<p><strong>Text2Cypher Prompt 解析</strong></p>
<p>任务阐述：根据自然语言询问生成图数据库查询语句</p>
<p>辅助信息：图数据库相关 schema；自然语言询问语句</p>
<p>约束限制：只能用提供 schema 中涉及的关系类型和属性</p>
<p>特殊提示：NebulaGraph 的 Cypher 方言规范（语言描述 + 举例说明）</p>
<ul>
<li>对比 Neo4j 图数据库的定制化提示模板，特殊提示中还可以添加：<ul>
<li>回答中不要包含解释或道歉</li>
<li>不要回答任何可能要求构建 Cypher 语句以外的问题</li>
<li>回答中不要包含除了生成的 Cypher 语句以外的内容</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ./llama_index/query_engine/knowledge_graph_query_engine.py</span></span><br><span class="line"></span><br><span class="line">DEFAULT_NEBULAGRAPH_NL2CYPHER_PROMPT_TMPL = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Generate NebulaGraph query from natural language.</span></span><br><span class="line"><span class="string">Use only the provided relationship types and properties in the schema.</span></span><br><span class="line"><span class="string">Do not use any other relationship types or properties that are not provided.</span></span><br><span class="line"><span class="string">Schema:</span></span><br><span class="line"><span class="string">---</span></span><br><span class="line"><span class="string">&#123;schema&#125;</span></span><br><span class="line"><span class="string">---</span></span><br><span class="line"><span class="string">Note: NebulaGraph speaks a dialect of Cypher, comparing to standard Cypher:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">it uses double equals sign for comparison: == rather than =</span></span><br><span class="line"><span class="string">it needs explicit label specification when referring to node properties, i.e.</span></span><br><span class="line"><span class="string">v is a variable of a node, and we know its label is Foo, v.foo.name is correct</span></span><br><span class="line"><span class="string">while v.name is not.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">For example, see this diff between standard and NebulaGraph Cypher dialect:</span></span><br><span class="line"><span class="string">```diff</span></span><br><span class="line"><span class="string">&lt; MATCH (p:person)-[:directed]-&gt;(m:movie) WHERE m.name = &#x27;The Godfather&#x27;</span></span><br><span class="line"><span class="string">&lt; RETURN p.name;</span></span><br><span class="line"><span class="string">---</span></span><br><span class="line"><span class="string">&gt; MATCH (p:`person`)-[:directed]-&gt;(m:`movie`) WHERE m.`movie`.`name` == &#x27;The Godfather&#x27;</span></span><br><span class="line"><span class="string">&gt; RETURN p.`person`.`name`;</span></span><br><span class="line"><span class="string">```</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Question: &#123;query_str&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">NebulaGraph Cypher dialect query:</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">DEFAULT_NEBULAGRAPH_NL2CYPHER_PROMPT = PromptTemplate(</span><br><span class="line">    DEFAULT_NEBULAGRAPH_NL2CYPHER_PROMPT_TMPL,</span><br><span class="line">    prompt_type=PromptType.TEXT_TO_GRAPH_QUERY,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h2 id="Graph-RAG-过程解析"><a href="#Graph-RAG-过程解析" class="headerlink" title="Graph RAG 过程解析"></a>Graph RAG 过程解析</h2><h3 id="Graph-RAG-for-LlamaIndex-Built-KG"><a href="#Graph-RAG-for-LlamaIndex-Built-KG" class="headerlink" title="Graph RAG for LlamaIndex Built KG"></a>Graph RAG for LlamaIndex Built KG</h3><p>对于基于已有的文档使用 LlamaIndex 构建的 KG，已经在构建时保存了相关索引，由 <code>KnowledgeGraphIndex</code> 类封装（<code>./llama_index/indices/knowledge_graph/base.py</code>），继承自 <code>BaseIndex</code> 类（<code>./llama_index/indices/base.py</code>）</p>
<ul>
<li>调用索引对象的 as_query_engine() 获得一个 <code>RetrieverQueryEngine</code> 类对象（<code>./llama_index/query_engine/retriever_query_engine.py</code>），继承自 BaseQueryEngine 类（<code>./llama_index/indices/query/base.py</code>）<ul>
<li>核心仍是由 <strong>Retriever</strong> 和 <strong>Response Synthesizer</strong> 构成</li>
<li>Retriever 由 KGTableRetriever 类对象承担（<code>./llama_index/indices/knowledge_graph/retrievers.py</code>），继承自 <code>BaseRetriever</code> 类（<code>./llama_index/indices/base_retriever.py</code>）</li>
<li>Response Synthesizer 的具体类型由 response_mode 参数决定，如本案例中使用了 TreeSummarize（<code>./llama_index/response_synthesizers/tree_summarize.py</code>），继承自 BaseSynthesizer（<code>./llama_index/response_synthesizers/base.py</code>）</li>
</ul>
</li>
<li>检索过程：（详见 <code>./llama_index/indices/knowledge_graph/retrievers.py</code> 中 <code>KGTableRetriever</code> 类的 <code>_retrieve</code> 方法）<ul>
<li>根据问题归纳相关关键词（由 LLM 完成）</li>
<li>根据关键词找到对应的实体</li>
<li>根据相关实体以固定深度提取 SubGraph</li>
<li>将 SubGraph 转换为上下文信息（字符串化等处理）</li>
</ul>
</li>
<li>回答整合过程：（详见 <code>./llama_index/response_synthesizers/tree_summarize.py</code> 中 <code>TreeSummarize</code> 类的 <code>get_response</code> 方法）</li>
</ul>
<h3 id="Graph-RAG-for-Existing-KG"><a href="#Graph-RAG-for-Existing-KG" class="headerlink" title="Graph RAG for Existing KG"></a>Graph RAG for Existing KG</h3><p>与 Graph RAG for LlamaIndex Built KG 流程基本相同，不同之处在于：</p>
<ul>
<li>前者 query_engine（包括其中的 retriever）直接通过索引构建，并且其 retriever 是一个 KGTableRetriever 对象</li>
<li>后者需要手动构建 retriever 和 query_engine，其中 retriever 是一个 KnowledgeGraphRAGRetriever 对象</li>
<li>两者 retriever 的实现方式不同，详见<code>./llama_index/indices/knowledge_graph/retrievers.py</code></li>
</ul>
<p>注：搜索相关实体的方式可以是基于关键字的提取，也可以是基于嵌入的提取，这由 <code>KnowledgeGraphRAGRetriever</code> 的参数 <code>retriever_mode</code> 控制，支持的选项有</p>
<ul>
<li>keyword</li>
<li>embedding（尚未实现）</li>
<li>keyword_embedding（尚未实现）</li>
</ul>
<h1 id="资料来源"><a href="#资料来源" class="headerlink" title="资料来源"></a>资料来源</h1><ul>
<li><a target="_blank" rel="noopener" href="https://www.siwei.io/graph-enabled-llama-index/">https://www.siwei.io/graph-enabled-llama-index/</a></li>
<li><a target="_blank" rel="noopener" href="https://www.siwei.io/llm-text-to-nebulagraph-query/">https://www.siwei.io/llm-text-to-nebulagraph-query/</a></li>
<li><a target="_blank" rel="noopener" href="https://www.siwei.io/graph-rag/">https://www.siwei.io/graph-rag/</a></li>
<li><a target="_blank" rel="noopener" href="https://www.siwei.io/demos/graph-rag/">https://www.siwei.io/demos/graph-rag/</a></li>
<li><a target="_blank" rel="noopener" href="https://gpt-index.readthedocs.io/en/stable/examples/query_engine/knowledge_graph_rag_query_engine.html">https://gpt-index.readthedocs.io/en/stable/examples/query_engine/knowledge_graph_rag_query_engine.html</a></li>
<li><a target="_blank" rel="noopener" href="https://www.siwei.io/demo-dumps/local-llm/Graph_RAG_Local.html">https://www.siwei.io/demo-dumps/local-llm/Graph_RAG_Local.html</a> （本地 LLM 构建案例）</li>
<li><a target="_blank" rel="noopener" href="https://github.com/jerryjliu/llama_index/tree/main/docs/examples/index_structs/knowledge_graph">https://github.com/jerryjliu/llama_index/tree/main/docs/examples/index_structs/knowledge_graph</a> （LlamaIndex KG）</li>
</ul>

        </div>

        
            <section class="post-copyright">
                
                    <p class="copyright-item">
                        <span>Author:</span>
                        <span>Yoson Ling</span>
                    </p>
                
                
                
                    <p class="copyright-item">
                        <span>License:</span>
                        <span>Copyright (c) 2019 <a target="_blank" rel="noopener" href="http://creativecommons.org/licenses/by-nc/4.0/">CC-BY-NC-4.0</a> LICENSE</span>
                    </p>
                
                

            </section>
        
        <section class="post-tags">
            <div>
                <span>Tag(s):</span>
                <span class="tag">
                    
                    
                        <a href="/tags/LLM/"># LLM</a>
                    
                        <a href="/tags/Docker/"># Docker</a>
                    
                        <a href="/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"># 知识图谱</a>
                    
                        <a href="/tags/%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93/"># 图数据库</a>
                    
                        <a href="/tags/NebulaGraph/"># NebulaGraph</a>
                    
                        <a href="/tags/RAG/"># RAG</a>
                    
                        <a href="/tags/Docker-Compose/"># Docker-Compose</a>
                    
                        <a href="/tags/LlamaIndex/"># LlamaIndex</a>
                    
                        
                </span>
            </div>
            <div>
                <a href="javascript:window.history.back();">back</a>
                <span>· </span>
                <a href="/">home</a>
            </div>
        </section>
        <section class="post-nav">
            
                <a class="prev" rel="prev" href="/2023/09/29/blog-deployment/">将博客同步部署到个人服务器</a>
            
            
            <a class="next" rel="next" href="/2023/08/02/LangChain-Learning-Notes/">LangChain 学习笔记</a>
            
        </section>


    </article>
</div>

            </div>
            <footer id="footer" class="footer">
    <div class="copyright">
        <span>© Yoson Ling | Powered by <a href="https://hexo.io" target="_blank">Hexo</a> & <a href="https://github.com/Siricee/hexo-theme-Chic" target="_blank">Chic</a></span>
    </div>
</footer>

    </div>
</body>

</html>